{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresiones + Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "# Cargo el módulo de numpy\n",
    "#-------------------------\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "#Si queremos que las imágenes sean mostradas en una ventana emergente quitar el inline\n",
    "%matplotlib  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de las clases\n",
    "#=========================\n",
    "\n",
    "# Definición de la clase para levantar (y dividir) los datos\n",
    "#===========================================================\n",
    "class Data(object):\n",
    "\n",
    "    def __init__(self, path):\n",
    "        self.dataset = self._build_dataset(path)\n",
    "\n",
    "    def _build_dataset(self, path):\n",
    "        # Armo una estructura de datos para guardarlos ahí\n",
    "        #-------------------------------------------------\n",
    "        structure = [('X1', np.float),\n",
    "                     ('X2', np.float),\n",
    "                     ('y', np.float)]\n",
    "        \n",
    "        # Abro el archivo lo recorro llenando la estructura creada línea a línea\n",
    "        #-----------------------------------------------------------------------\n",
    "        with open(path, encoding=\"utf8\") as data_csv:\n",
    "\n",
    "            data_gen = ((float(line.split(',')[0]), float(line.split(',')[1]), float(line.split(',')[2])) # add here + 10 in second value\n",
    "                        for i, line in enumerate(data_csv) if i != 0)\n",
    "            embeddings = np.fromiter(data_gen, structure)\n",
    "\n",
    "        return embeddings\n",
    "    \n",
    "    # Separo los los datos (train y test)\n",
    "    #------------------------------------\n",
    "    def split(self, percentage): # 0.8\n",
    "        X1 = self.dataset['X1']\n",
    "        X2 = self.dataset['X2']\n",
    "        y = self.dataset['y']\n",
    "\n",
    "        permuted_idxs = np.random.permutation(X1.shape[0])\n",
    "\n",
    "        train_idxs = permuted_idxs[0:int(percentage * X1.shape[0])]\n",
    "\n",
    "        test_idxs = permuted_idxs[int(percentage * X1.shape[0]): X1.shape[0]]\n",
    "\n",
    "        X_train = np.vstack((X1[train_idxs],X2[train_idxs]))\n",
    "        X_test = np.vstack((X1[test_idxs],X2[test_idxs]))\n",
    "\n",
    "        y_train = y[train_idxs]\n",
    "        y_test = y[test_idxs]\n",
    "\n",
    "        return X_train, X_test, y_train, y_test\n",
    "                        \n",
    "                        \n",
    "# Clase base de la que heredan las que vayamos implementando\n",
    "#-----------------------------------------------------------\n",
    "# Es conveniente tener una clase base de la que vayan heredando las demás. Siempre habrá un método fit\n",
    "# y un método predict. Pero en esta clase base puede haber definiciones de atributos comunes a todas\n",
    "#===========================================================\n",
    "class BaseModel(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        return NotImplemented\n",
    "\n",
    "    def predict(self, X):\n",
    "        return NotImplemented\n",
    "\n",
    "\n",
    "class ConstantModel(BaseModel):\n",
    "    # El modelo constante solo saca la media de los datos y devuelve ese valor\n",
    "    # Es útil para comparar. Ningún modelo debería ser peor que este.\n",
    "    #-------------------------------------------------------------------------\n",
    "    def fit(self, X, Y):\n",
    "        W = Y.mean()\n",
    "        self.model = W\n",
    "\n",
    "    def predict(self, X):\n",
    "        # La \"predicción\" consiste en devolver la media para todos los valores\n",
    "        return np.ones(len(X)) * self.model\n",
    "\n",
    "# Modelo de la regresión lineal\n",
    "#==============================\n",
    "class LinearRegression(BaseModel):\n",
    "    # Este modelo de regresión lineal ajusta únicamente la pendiente, no contempla la ordenada al origen\n",
    "    def fit(self, X, y):\n",
    "        # Verificamos si X es un vector o una matriz\n",
    "        if len(X.shape) == 1:\n",
    "            # Esta es una manera de escribir la pseudo-inversa (X'.X)^(-1).X'.y\n",
    "            W = X.T.dot(y) / X.T.dot(X)\n",
    "        else:\n",
    "            # Y esta es la manera con matrices\n",
    "            W = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "        self.model = W\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model * X\n",
    "    \n",
    "# Modelo que incluye la ordenada al origen (b)\n",
    "# ============================================\n",
    "class LinearRegressionWithB(BaseModel):\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # En el caso de ajustar con ordenada al origen le agregamos la columna de b con unos\n",
    "        # (Le agrega la fila abajo y luego traspongo --> Vectores columna)\n",
    "        X_expanded = np.vstack((X, np.ones(len(X)))).T\n",
    "        W = np.linalg.inv(X_expanded.T.dot(X_expanded)).dot(X_expanded.T).dot(y)\n",
    "        self.model = W\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_expanded = np.vstack((X, np.ones(len(X)))).T\n",
    "        return X_expanded.dot(self.model)\n",
    "\n",
    "# Modelo de la regresión cuadrática\n",
    "#==================================\n",
    "class QuadraticRegression(BaseModel):\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Armamos la matriz de ajuste\n",
    "        X_expanded = np.vstack((X**2, X, np.ones(len(X)))).T\n",
    "        W = np.linalg.inv(X_expanded.T.dot(X_expanded)).dot(X_expanded.T).dot(y)\n",
    "        \n",
    "        self.model = W\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_expanded = np.vstack((X**2, X, np.ones(len(X)))).T\n",
    "        return X_expanded.dot(self.model)\n",
    "\n",
    "# Modelo de la regresión cuadrática\n",
    "#==================================\n",
    "class PolyRegression(BaseModel):\n",
    "    \n",
    "    def fit(self, X, y, n):\n",
    "        # Tomo X y le agrego el término independiente\n",
    "        X_expanded = np.vstack((X, np.ones(len(X))))\n",
    "        for i in range(n-1):\n",
    "            # Armamos la matriz de ajuste a partir del grado del polinomio\n",
    "            X_n = X**(n-i)\n",
    "            X_expanded = np.vstack((X_n, X_expanded))\n",
    "         \n",
    "        X_expanded = X_expanded.T\n",
    "            \n",
    "        W = np.linalg.inv(X_expanded.T.dot(X_expanded)).dot(X_expanded.T).dot(y)\n",
    "        \n",
    "        self.model = W\n",
    "\n",
    "    def predict(self, X, n):\n",
    "        # Tomo X y le agrego el término independiente\n",
    "        X_expanded = np.vstack((X, np.ones(len(X))))\n",
    "        for i in range(n-1):\n",
    "            # Armamos la matriz de ajuste a partir del grado del polinomio\n",
    "            X_n = X**(n-i)\n",
    "            X_expanded = np.vstack((X_n, X_expanded))\n",
    "         \n",
    "        X_expanded = X_expanded.T\n",
    "        \n",
    "        return X_expanded.dot(self.model)\n",
    "    \n",
    "    \n",
    "# Clases de métricas\n",
    "#===================\n",
    "\n",
    "# Clase madre\n",
    "class Metric(object):\n",
    "    def __call__(self, target, prediction):\n",
    "        return NotImplemented\n",
    "\n",
    "# Por ahora solo esta --> Error cuadrático medio\n",
    "class MSE(Metric):\n",
    "    def __call__(self, target, prediction):\n",
    "        n = target.size\n",
    "        return np.sum((target - prediction) ** 2) / n\n",
    "\n",
    "class Precision(Metric):\n",
    "    def __call__(self, truth, prediction):\n",
    "        \n",
    "        # Encontramos los True Positive\n",
    "        true_pos_mask = (prediction == 1) & (truth == 1)\n",
    "        true_pos = true_pos_mask.sum()\n",
    "        \n",
    "        # Encontramos los False Positive\n",
    "        false_pos_mask = (prediction == 1) & (truth == 0)\n",
    "        false_pos = false_pos_mask.sum()\n",
    "        \n",
    "        return true_pos / (true_pos + false_pos)\n",
    "\n",
    "class Recall (Metric):\n",
    "    def __call__(self, truth, prediction):\n",
    "        \n",
    "        # Encontramos los True Positive\n",
    "        true_pos_mask = (prediction == 1) & (truth == 1)\n",
    "        true_pos = true_pos_mask.sum()\n",
    "        \n",
    "        # Encontramos los False Negative\n",
    "        false_neg_mask = (prediction == 0) & (truth == 1)\n",
    "        false_neg = false_neg_mask.sum()\n",
    "        \n",
    "        return true_pos / (true_pos + false_neg)\n",
    "        \n",
    "class Accuracy (Metric):\n",
    "    def __call__(self, truth, prediction):\n",
    "        \n",
    "        # Encontramos los True Positive\n",
    "        true_pos_mask = (prediction == 1) & (truth == 1)\n",
    "        true_pos = true_pos_mask.sum()\n",
    "        \n",
    "        # Encontramos los False Positive\n",
    "        false_pos_mask = (prediction == 1) & (truth == 0)\n",
    "        false_pos = false_pos_mask.sum()\n",
    "        \n",
    "        # Encontramos los True Negative\n",
    "        true_neg_mask = (prediction == 0) & (truth == 0)\n",
    "        true_neg = true_neg_mask.sum() \n",
    "    \n",
    "        # Encontramos los False Negative\n",
    "        false_neg_mask = (prediction == 0) & (truth == 1)\n",
    "        false_neg = false_neg_mask.sum()\n",
    "    \n",
    "        return (true_pos + true_neg) / (true_pos + true_neg + false_pos + false_neg)\n",
    "\n",
    "def k_folds(X_train, y_train, k=5):\n",
    "    l_regression = LinearRegression()\n",
    "    error = MSE()\n",
    "\n",
    "    chunk_size = int(len(X_train) / k)\n",
    "    mse_list = []\n",
    "    for i in range(0, len(X_train), chunk_size):\n",
    "        end = i + chunk_size if i + chunk_size <= len(X_train) else len(X_train)\n",
    "        new_X_valid = X_train[i: end]\n",
    "        new_y_valid = y_train[i: end]\n",
    "        new_X_train = np.concatenate([X_train[: i], X_train[end:]])\n",
    "        new_y_train = np.concatenate([y_train[: i], y_train[end:]])\n",
    "\n",
    "        l_regression.fit(new_X_train, new_y_train)\n",
    "        prediction = l_regression.predict(new_X_valid)\n",
    "        mse_list.append(error(new_y_valid, prediction))\n",
    "\n",
    "    mean_MSE = np.mean(mse_list)\n",
    "\n",
    "    return mean_MSE\n",
    "    \n",
    "    \n",
    "def gradient_descent(X_train, y_train, lr=0.01, amt_epochs=100):\n",
    "    \"\"\"\n",
    "    lr: learning rate\n",
    "    amt_epochs: cantidad de iteraciones\n",
    "    \n",
    "    shapes: \n",
    "        X_t: nxm\n",
    "        Y_y: nx1\n",
    "        W: mx1\n",
    "    \"\"\"\n",
    "    n = X_train.shape[0]\n",
    "    m = X_train.shape[1]\n",
    "    # print('X.shape:{}x{}\\n'.format(n,m))\n",
    "        \n",
    "    # Inicializamos los pesos\n",
    "    W = np.random.randn(m).reshape(m,1)\n",
    "    print('W_inicial_{}'.format(W.reshape(-1)))\n",
    "    \n",
    "    for i in range(amt_epochs):\n",
    "        # Calculo la estimación\n",
    "        #y_hat=X_train*W\n",
    "        y_hat=np.matmul(X_train,W)\n",
    "        \n",
    "        # Calculo el error\n",
    "        error=y_train-y_hat\n",
    "        \n",
    "        # Calculo el gradiente\n",
    "        grad_sum = np.sum(error*X_train,axis=0)\n",
    "        grad_mul =-2/n*grad_sum  #1xm\n",
    "        gradient = np.transpose(grad_mul).reshape(-1,1) #mx1\n",
    "        \n",
    "        # Actualizo el valor\n",
    "        W = W - (lr*gradient)\n",
    "    \n",
    "    return W\n",
    "\n",
    "\n",
    "def stochastic_gradient_descent(X_train, y_train, lr=0.01, amt_epochs=100):\n",
    "    \"\"\"\n",
    "    lr: learning rate\n",
    "    amt_epochs: cantidad de iteraciones\n",
    "    \n",
    "    shapes: \n",
    "        X_t: nxm\n",
    "        Y_y: nx1\n",
    "        W: mx1\n",
    "    \"\"\"\n",
    "    n = X_train.shape[0]\n",
    "    m = X_train.shape[1]\n",
    "    # print('X.shape:{}x{}\\n'.format(n,m))\n",
    "        \n",
    "    # Inicializamos los pesos\n",
    "    W = np.random.randn(m).reshape(m,1)\n",
    "    print('W_inicial_{}'.format(W.reshape(-1)))\n",
    "    \n",
    "    for i in range(amt_epochs):\n",
    "        idx=np.random.permutation(X_train.shape[0])\n",
    "        X_train = X_train[idx]\n",
    "        y_train = y_train[idx]\n",
    "        \n",
    "        for j in range(n):\n",
    "        \n",
    "            # Calculo la estimación\n",
    "            #y_hat=X_train*W\n",
    "            y_hat=np.matmul(X_train[j].reshape(1,-1),W)\n",
    "\n",
    "            # Calculo el error\n",
    "            error=y_train[j]-y_hat\n",
    "\n",
    "            # Calculo el gradiente\n",
    "            grad_sum = error*X_train[j]\n",
    "            grad_mul =-2/n*grad_sum  #1xm\n",
    "            gradient = np.transpose(grad_mul).reshape(-1,1) #mx1\n",
    "\n",
    "            # Actualizo el valor\n",
    "            W = W - (lr*gradient)\n",
    "    \n",
    "    return W\n",
    "\n",
    "def mini_batch_gradient_descent(X_train, y_train, lr=0.01, amt_epochs=100):\n",
    "    \"\"\"\n",
    "    shapes:\n",
    "        X_t = nxm\n",
    "        y_t = nx1\n",
    "        W = mx1\n",
    "    \"\"\"\n",
    "    b = 16\n",
    "    n = X_train.shape[0]\n",
    "    m = X_train.shape[1]\n",
    "\n",
    "    # initialize random weights\n",
    "    W = np.random.randn(m).reshape(m, 1)\n",
    "\n",
    "    for i in range(amt_epochs):\n",
    "        idx = np.random.permutation(X_train.shape[0])\n",
    "        X_train = X_train[idx]\n",
    "        y_train = y_train[idx]\n",
    "\n",
    "        batch_size = int(len(X_train) / b)\n",
    "        for i in range(0, len(X_train), batch_size):\n",
    "            end = i + batch_size if i + batch_size <= len(X_train) else len(X_train)\n",
    "            batch_X = X_train[i: end]\n",
    "            batch_y = y_train[i: end]\n",
    "\n",
    "            prediction = np.matmul(batch_X, W)  # nx1\n",
    "            error = batch_y - prediction  # nx1\n",
    "\n",
    "            grad_sum = np.sum(error * batch_X, axis=0)\n",
    "            grad_mul = -2/n * grad_sum  # 1xm\n",
    "            gradient = np.transpose(grad_mul).reshape(-1, 1)  # mx1\n",
    "\n",
    "            W = W - (lr * gradient)\n",
    "\n",
    "    return W\n",
    "\n",
    "\n",
    "def mini_batch_logistic_gradient_descent(X_train, y_train, lr=0.01, amt_epochs=100):\n",
    "    \"\"\"\n",
    "    shapes:\n",
    "        X_t = nxm\n",
    "        y_t = nx1\n",
    "        W = mx1\n",
    "    \"\"\"\n",
    "    b = 16\n",
    "    n = X_train.shape[0]\n",
    "    m = X_train.shape[1]\n",
    "\n",
    "    # initialize random weights\n",
    "    W = np.random.randn(m).reshape(m, 1)\n",
    "\n",
    "    for i in range(amt_epochs):\n",
    "        idx = np.random.permutation(X_train.shape[0])\n",
    "        X_train = X_train[idx]\n",
    "        y_train = y_train[idx]\n",
    "\n",
    "        batch_size = int( len(X_train) / b)\n",
    "        for i in range(0, len(X_train), batch_size):\n",
    "            end = i + batch_size if i + batch_size <= len(X_train) else len(X_train)\n",
    "            batch_X = X_train[i: end]\n",
    "            batch_y = y_train[i: end]\n",
    "            prediction = 1/(1+np.exp(-np.matmul(batch_X, W))) #Ojo que no es la predicción posta!!\n",
    "            error = batch_y - prediction  # nx1\n",
    "\n",
    "            grad_sum = np.sum(error * batch_X, axis=0)\n",
    "            grad_mul = -2/n * grad_sum  # 1xm\n",
    "            gradient = np.transpose(grad_mul).reshape(-1, 1)  # mx1\n",
    "\n",
    "            W = W - (lr * gradient)\n",
    "\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W encontrado: [[ 0.00685739]\n",
      " [-0.00022121]]\n",
      "\n",
      "\n",
      " Precisión: 0.8333333333333334 \n",
      "\n",
      " Accuracy: 0.6363636363636364  \n",
      "\n",
      " Recall: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Armamos el main\n",
    "#----------------\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # Llamo al dataset sobre el que voy a trabajar\n",
    "    #---------------------------------------------\n",
    "    dataset = Data('../clase_6_dataset.txt')\n",
    "       \n",
    "    # Hacemos la partición del dataset\n",
    "    #---------------------------------\n",
    "    X_train, X_test, y_train, y_test = dataset.split(1)\n",
    "    \n",
    "    lr_1 = 0.001\n",
    "    amp_epochs_1=1000\n",
    "    W = mini_batch_logistic_gradient_descent(X_train.T, y_train.reshape(-1,1), lr=lr_1, amt_epochs=amp_epochs_1)\n",
    "    \n",
    "    print('W encontrado: {}'.format(W))\n",
    "    \n",
    "    # Calculo la predicción (lo hago acá en el ruedo pero en rigor debería crear una def) \n",
    "    prediction = (np.matmul(X_train.T,W) > 0.5)\n",
    "    truth = y_train.reshape(-1,1)\n",
    "    \n",
    "    # CALCULAR LAS MÉTRICAS\n",
    "    precision = Precision()\n",
    "    accuracy = Accuracy()\n",
    "    recall = Recall()\n",
    "    \n",
    "    prec_test = precision(truth,prediction)\n",
    "    acc_test = accuracy(truth,prediction)\n",
    "    rec_test = recall(truth,prediction)\n",
    "    print ('\\n\\n Precisión: {} \\n\\n Accuracy: {}  \\n\\n Recall: {}'.format(prec_test,acc_test,rec_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Cambio a tema oscuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!jt -t chesterish\n",
    "#!jt -t monokai\n",
    "#!jt -t solarizedd -f fira -fs 115\n",
    "!jt -t oceans16 -T -N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
