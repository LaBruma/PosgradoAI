{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación de una red neuronal con dos capas ocultas y mini-batch (indexada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    out = 1/(1 + np.exp(-z))\n",
    "    return out\n",
    "\n",
    "def trainNN_mini_batch(X, y, lr=0.01, amt_epochs=100, n_batchs=16):\n",
    "    \n",
    "    global J_train\n",
    "    global J_valid\n",
    "    \n",
    "    # Inicializamos aleatoriamente los parámatros\n",
    "    #============================================\n",
    "    W1 = np.random.rand(2,3)\n",
    "    W2 = np.random.rand(3,2)\n",
    "    W3 = np.random.rand(2,1)\n",
    "    b1 = np.random.rand(3,1)\n",
    "    b2 = np.random.rand(2,1)\n",
    "    b3 = np.random.rand()\n",
    "    \n",
    "    # Separo una parte de los datos para validation\n",
    "    #----------------------------------------------\n",
    "    permuted_idxs = np.random.permutation(X.shape[0])\n",
    "    train_ids = permuted_idxs[0:int(0.8 * X.shape[0])]\n",
    "    valid_ids = permuted_idxs[int(0.8 * X.shape[0]): X.shape[0]]\n",
    "    X_train = X[train_ids]\n",
    "    X_valid = X[valid_ids]\n",
    "    y_train = y[train_ids]\n",
    "    y_valid = y[valid_ids]\n",
    "    \n",
    "    # Algunas valores que nos van a servir\n",
    "    #-------------------------------------\n",
    "    n = X_train.shape[0]\n",
    "    nv = X_valid.shape[0]\n",
    "    batch_size = int(len(X_train) / n_batchs) # Paso o tamaño en muestras del batch\n",
    "    batch_idxs = np.arange(0, n-n_batchs, n_batchs)    # Indices para tomar las muestras de los batchs\n",
    "    \n",
    "    # Inicializo los vectores de datos\n",
    "    J_train = []\n",
    "    J_valid = []\n",
    "    \n",
    "    # Primer for con las iteraciones\n",
    "    #-------------------------------\n",
    "    for i in range (amt_epochs):\n",
    "        \n",
    "        # Inicializo la integral de pesos del batch\n",
    "        J_int = 0\n",
    "        \n",
    "        # Permutamos los índices de los datos de entrenamiento (mezclamos)\n",
    "        idx = np.random.permutation(X_train.shape[0])\n",
    "        X_train = X_train[idx]\n",
    "        y_train = y_train[idx]\n",
    "        \n",
    "        # Segundo for para el batch armado\n",
    "        for j in range(n_batchs):\n",
    "            \n",
    "            # Armo el mini batch de la iteración en cuestión\n",
    "            X_batch = X_train[batch_idxs+j,:]\n",
    "            y_batch = y_train[batch_idxs+j]\n",
    "            \n",
    "            # Forward\n",
    "            #--------\n",
    "            z1 = W1.T @ X_batch.T + b1\n",
    "            a1 = sigmoid(z1)\n",
    "            z2 = W2.T @ a1 + b2\n",
    "            a2 = sigmoid(z2)\n",
    "            z3 = W3.T @ a2 + b3          \n",
    "            y_hat = sigmoid(z3)\n",
    "            # Calculo el error del pasaje \"forward\" en esta corrida\n",
    "            J = (1/batch_size) * np.sum(np.power(y_batch-y_hat,2))\n",
    "            \n",
    "            # Backpropagation\n",
    "            #----------------\n",
    "            # Output layer\n",
    "            dz3 = -2*(y_batch-y_hat) * y_hat * (1-y_hat)\n",
    "            grad_W3 = (1/batch_size) * dz3 @ a2.T\n",
    "            grad_b3 = (1/batch_size) * np.sum(dz3,axis=1,keepdims=True)\n",
    "            \n",
    "            # Hidden layer: Layer 2\n",
    "            dz2 = np.multiply(W3 @ dz3, (a2*(1-a2)))\n",
    "            grad_W2 = (1/batch_size) * dz2 @ a1.T\n",
    "            grad_b2 = (1/batch_size) * np.sum(dz2,axis=1,keepdims=True)\n",
    "            \n",
    "            # Hidden layer: Layer 1\n",
    "            dz1 = np.multiply(W2 @ dz2, (a1*(1-a1)))\n",
    "            grad_W1 = (1/batch_size) * dz1 @ X_batch\n",
    "            grad_b1 = (1/batch_size) * np.sum(dz1,axis=1,keepdims=True)\n",
    "            \n",
    "            # Updates\n",
    "            W3 = W3 - lr * grad_W3.T * J\n",
    "            W2 = W2 - lr * grad_W2.T * J\n",
    "            W1 = W1 - lr * grad_W1.T * J\n",
    "            b3 = b3 - lr * grad_b3 * J\n",
    "            b2 = b2 - lr * grad_b2 * J\n",
    "            b1 = b1 - lr * grad_b1 * J\n",
    "            \n",
    "            J_int = J_int + J\n",
    "\n",
    "        # Calculo el error sobre el set de validación\n",
    "        z1 = W1.T @ X_valid.T + b1\n",
    "        a1 = sigmoid(z1)\n",
    "        z2 = W2.T @ a1 + b2\n",
    "        a2 = sigmoid(z2)\n",
    "        z3 = W3.T @ a2 + b3          \n",
    "        y_hat = sigmoid(z3)\n",
    "        \n",
    "        J_valid.append( (1/nv) * np.sum(np.power(y_valid-y_hat,2)) )\n",
    "        \n",
    "        # Guardo el valor de la función de costo a la salida de cada batch\n",
    "        J_train.append(J_int/n_batchs)\n",
    "        \n",
    "    return W1,W2,W3,b1,b2,b3\n",
    "\n",
    "def testNetwork(W1,W2,W3,b1,b2,b3,X_test):\n",
    "    n = X_test.shape[0]\n",
    "    y_hat = np.zeros((n,1), dtype=float)\n",
    "    for i in range(n):\n",
    "        z1 = W1.T @ X_test.T + b1\n",
    "        a1 = sigmoid(z1)\n",
    "        z2 = W2.T @ a1 + b2\n",
    "        a2 = sigmoid(z2)\n",
    "        z3 = W3.T @ a2 + b3          \n",
    "        y_hat = sigmoid(z3)\n",
    "    \n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos los datos de entrenamiento\n",
    "#------------------------------------\n",
    "data = pd.read_csv(\"train_data.csv\",skiprows = 0)\n",
    "data = np.array(data)\n",
    "\n",
    "# Entrenamos la red\n",
    "#------------------\n",
    "X = data[:,:2]\n",
    "y = data[:,2]\n",
    "W1,W2,W3,b1,b2,b3 = trainNN_mini_batch(X, y, lr=0.1, amt_epochs=5000, n_batchs = 16)\n",
    "\n",
    "# Ploteamos la evolución del costo en el aprendizaje\n",
    "#---------------------------------------------------\n",
    "plt.plot(J_train,'r')\n",
    "plt.plot(J_valid,'b')\n",
    "plt.gca().set_title('Evolución función de costo')\n",
    "plt.legend(['Error de entrenamiento','Error de validación'])\n",
    "plt.xlabel('Iteraciones')\n",
    "plt.ylabel('Costo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.778679   0.10962515 0.48675079 0.18609741 0.12704348 0.8227204\n",
      "  0.10732736 0.1024297  0.49259677 0.92864254 0.55856237 0.90811911\n",
      "  0.10565094 0.72735101 0.11182225 0.14542787 0.75122687 0.93101283\n",
      "  0.12836694 0.87187078 0.93303301 0.10680888 0.15398035 0.13569608\n",
      "  0.69905637 0.65138513 0.92055038 0.91477996 0.12516767 0.57012168\n",
      "  0.66791932 0.92542754 0.24365587 0.7143638  0.35050239 0.8064423\n",
      "  0.58209571 0.93515322 0.86180236 0.11696609 0.10558875 0.29104735\n",
      "  0.1192831  0.11588428 0.57973675 0.11015253 0.91278084 0.91139263\n",
      "  0.11953634 0.28647783 0.18528015 0.13951102 0.12104617 0.14593214\n",
      "  0.9140004  0.16324257 0.15877189 0.6360217  0.89242203 0.10481367\n",
      "  0.15728512 0.90101622 0.1059703  0.92015808 0.11820755 0.89611648\n",
      "  0.92568338 0.10658159 0.13500698 0.10349754 0.90053988 0.22880032\n",
      "  0.76625707 0.17994889 0.62196205 0.59950059 0.2091024  0.84362845\n",
      "  0.80195252 0.45743971 0.91684543 0.91529955 0.91317227 0.87163912\n",
      "  0.59672935 0.86198705 0.9247037  0.12402062 0.90506084 0.17910872\n",
      "  0.88635635 0.11766269 0.82566392 0.28862837 0.67390685 0.91333507\n",
      "  0.1112829  0.91848205 0.10612746 0.92446892]]\n",
      "[1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0.\n",
      " 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1.\n",
      " 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1.\n",
      " 0. 1. 0. 1.]\n",
      "5.23770982139451\n"
     ]
    }
   ],
   "source": [
    "# Cargamos los datos de testeo\n",
    "#-----------------------------\n",
    "data = pd.read_csv(\"test_data.csv\",skiprows = 0)\n",
    "data = np.array(data)\n",
    "X = data[:,:2]\n",
    "y = data[:,2]\n",
    "\n",
    "# Testeamos la red con los pesos aprendidos\n",
    "#------------------------------------------\n",
    "y_guess = testNetwork(W1,W2,W3,b1,b2,b3,X)\n",
    "print(y_guess)\n",
    "print(y)\n",
    "print(np.sum(y-y_guess))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusiones\n",
    "- Se comprueba que la función de costo va disminuyendo con las iteraciones.\n",
    "- Se observan dos escalones (de la función de costo), uno inicial y otro alrededor de la iteración 500 (en algunas corridas estos dos pasos son más marcados)\n",
    "- Al testear la red no se equivoca en ninguna salida...pero tengo dudas sobre:\n",
    "    - ¿Por qué no llega la sigmoidea a saturar? (no llego a tener 1s y 0s en y_guess)\n",
    "    - ¿Por qué se precisa de un learning rate tan alto?...bah...¿es alto?\n",
    "    - ¿Por qué se precisa de tantas iteraciones?\n",
    "    - ¿Cómo elegiría la cantidad de batchs? en 8 más o menos funciona\n",
    "    - ¿Me estoy equivocando en algo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
