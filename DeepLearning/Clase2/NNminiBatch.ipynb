{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación de una red neuronal con dos capas ocultas y mini-batch (indexada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    out = 1/(1 + np.exp(-z))\n",
    "    return out\n",
    "\n",
    "def trainNN_mini_batch(X, y, lr=0.01, amt_epochs=100, n_batchs=16):\n",
    "    \n",
    "    global J_train\n",
    "    global J_valid\n",
    "    \n",
    "    # Inicializamos aleatoriamente los parámatros\n",
    "    #============================================\n",
    "    W1 = np.random.rand(2,3)\n",
    "    W2 = np.random.rand(3,2)\n",
    "    W3 = np.random.rand(2,1)\n",
    "    b1 = np.random.rand(3,1)\n",
    "    b2 = np.random.rand(2,1)\n",
    "    b3 = np.random.rand()\n",
    "    \n",
    "    # Separo una parte de los datos para validation\n",
    "    #----------------------------------------------\n",
    "    permuted_idxs = np.random.permutation(X.shape[0])\n",
    "    train_ids = permuted_idxs[0:int(0.8 * X.shape[0])]\n",
    "    valid_ids = permuted_idxs[int(0.8 * X.shape[0]): X.shape[0]]\n",
    "    X_train = X[train_ids]\n",
    "    X_valid = X[valid_ids]\n",
    "    y_train = y[train_ids]\n",
    "    y_valid = y[valid_ids]\n",
    "    \n",
    "    # Algunas valores que nos van a servir\n",
    "    #-------------------------------------\n",
    "    n = X_train.shape[0]m\n",
    "    nv = X_valid.shape[0]\n",
    "    batch_size = int(len(X_train) / n_batchs) # Paso o tamaño en muestras del batch\n",
    "    batch_idxs = np.arange(0, n-n_batchs, n_batchs)    # Indices para tomar las muestras de los batchs\n",
    "    \n",
    "    # Inicializo los vectores de datos\n",
    "    J_train = []\n",
    "    J_valid = []\n",
    "    \n",
    "    # Primer for con las iteraciones\n",
    "    #-------------------------------\n",
    "    for i in range (amt_epochs):\n",
    "        \n",
    "        # Inicializo la integral de pesos del batch\n",
    "        J_int = 0\n",
    "        \n",
    "        # Permutamos los índices de los datos de entrenamiento (mezclamos)\n",
    "        idx = np.random.permutation(X_train.shape[0])\n",
    "        X_train = X_train[idx]\n",
    "        y_train = y_train[idx]\n",
    "        \n",
    "        # Segundo for para el batch armado\n",
    "        for j in range(n_batchs):\n",
    "            \n",
    "            # Armo el mini batch de la iteración en cuestión\n",
    "            X_batch = X_train[batch_idxs+j,:]\n",
    "            y_batch = y_train[batch_idxs+j]\n",
    "            \n",
    "            # Forward\n",
    "            #--------\n",
    "            z1 = W1.T @ X_batch.T + b1\n",
    "            a1 = sigmoid(z1)\n",
    "            z2 = W2.T @ a1 + b2\n",
    "            a2 = sigmoid(z2)\n",
    "            z3 = W3.T @ a2 + b3          \n",
    "            y_hat = sigmoid(z3)\n",
    "            # Calculo el error del pasaje \"forward\" en esta corrida\n",
    "            J = (1/batch_size) * np.sum(np.power(y_batch-y_hat,2))\n",
    "            \n",
    "            # Backpropagation\n",
    "            #----------------\n",
    "            # Output layer\n",
    "            dz3 = -2*(y_batch-y_hat) * y_hat * (1-y_hat)\n",
    "            grad_W3 = (1/batch_size) * dz3 @ a2.T\n",
    "            grad_b3 = (1/batch_size) * np.sum(dz3,axis=1,keepdims=True)\n",
    "            \n",
    "            # Hidden layer: Layer 2\n",
    "            dz2 = np.multiply(W3 @ dz3, (a2*(1-a2)))\n",
    "            grad_W2 = (1/batch_size) * dz2 @ a1.T\n",
    "            grad_b2 = (1/batch_size) * np.sum(dz2,axis=1,keepdims=True)\n",
    "            \n",
    "            # Hidden layer: Layer 1\n",
    "            dz1 = np.multiply(W2 @ dz2, (a1*(1-a1)))\n",
    "            grad_W1 = (1/batch_size) * dz1 @ X_batch\n",
    "            grad_b1 = (1/batch_size) * np.sum(dz1,axis=1,keepdims=True)\n",
    "            \n",
    "            # Updates\n",
    "            W3 = W3 - lr * grad_W3.T * J\n",
    "            W2 = W2 - lr * grad_W2.T * J\n",
    "            W1 = W1 - lr * grad_W1.T * J\n",
    "            b3 = b3 - lr * grad_b3 * J\n",
    "            b2 = b2 - lr * grad_b2 * J\n",
    "            b1 = b1 - lr * grad_b1 * J\n",
    "            \n",
    "            J_int = J_int + J\n",
    "\n",
    "        # Calculo el error sobre el set de validación\n",
    "        z1 = W1.T @ X_valid.T + b1\n",
    "        a1 = sigmoid(z1)\n",
    "        z2 = W2.T @ a1 + b2\n",
    "        a2 = sigmoid(z2)\n",
    "        z3 = W3.T @ a2 + b3          \n",
    "        y_hat = sigmoid(z3)\n",
    "        \n",
    "        J_valid.append( (1/nv) * np.sum(np.power(y_valid-y_hat,2)) )\n",
    "        \n",
    "        # Guardo el valor de la función de costo a la salida de cada batch\n",
    "        J_train.append(J_int/n_batchs)\n",
    "        \n",
    "    return W1,W2,W3,b1,b2,b3\n",
    "\n",
    "def testNetwork(W1,W2,W3,b1,b2,b3,X_test):\n",
    "    n = X_test.shape[0]\n",
    "    y_hat = np.zeros((n,1), dtype=float)\n",
    "    for i in range(n):\n",
    "        z1 = W1.T @ X_test.T + b1\n",
    "        a1 = sigmoid(z1)\n",
    "        z2 = W2.T @ a1 + b2\n",
    "        a2 = sigmoid(z2)\n",
    "        z3 = W3.T @ a2 + b3          \n",
    "        y_hat = sigmoid(z3)\n",
    "    \n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos los datos de entrenamiento\n",
    "#------------------------------------\n",
    "data = pd.read_csv(\"train_data.csv\",skiprows = 0)\n",
    "data = np.array(data)\n",
    "\n",
    "# Entrenamos la red\n",
    "#------------------\n",
    "X = data[:,:2]\n",
    "y = data[:,2]\n",
    "W1,W2,W3,b1,b2,b3 = trainNN_mini_batch(X, y, lr=0.25, amt_epochs=30000, n_batchs = 24)\n",
    "\n",
    "# Ploteamos la evolución del costo en el aprendizaje\n",
    "#---------------------------------------------------\n",
    "plt.plot(J_train,'r')\n",
    "plt.plot(J_valid,'b')\n",
    "plt.gca().set_title('Evolución función de costo')\n",
    "plt.legend(['Error de entrenamiento','Error de validación'])\n",
    "plt.xlabel('Iteraciones')\n",
    "plt.ylabel('Costo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.98823069 0.04565422 0.05730226 0.02347417 0.01422017 0.99100745\n",
      "  0.02332772 0.00582104 0.09245874 0.9835805  0.96336013 0.98688452\n",
      "  0.00698958 0.40828515 0.07194554 0.01562974 0.97642829 0.98166711\n",
      "  0.3669129  0.99348651 0.99685568 0.02308176 0.46783242 0.00564427\n",
      "  0.98714483 0.9614045  0.98290925 0.93253562 0.00880174 0.95578229\n",
      "  0.09386216 0.97044178 0.94693808 0.98913756 0.0376354  0.97052663\n",
      "  0.98482321 0.9981072  0.97208409 0.15207439 0.00578608 0.0389664\n",
      "  0.0242606  0.02797548 0.97886972 0.00885861 0.85538623 0.76946526\n",
      "  0.01124647 0.95903501 0.00622604 0.24559102 0.00658242 0.0124565\n",
      "  0.93393223 0.60534114 0.00856335 0.95813566 0.61363593 0.00650734\n",
      "  0.6864087  0.98252032 0.0072688  0.97284577 0.02645906 0.97075375\n",
      "  0.96092772 0.00747401 0.01375153 0.00996646 0.97457348 0.7724674\n",
      "  0.99042837 0.01908088 0.98922308 0.98070241 0.02284078 0.9680797\n",
      "  0.32864542 0.75114637 0.876464   0.98489413 0.8977348  0.94686783\n",
      "  0.98083494 0.43362743 0.98750629 0.04197907 0.98618972 0.01951143\n",
      "  0.67896641 0.00777148 0.9912642  0.07630085 0.98469751 0.97687938\n",
      "  0.0362472  0.99313878 0.02218897 0.94319441]]\n",
      "[1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0.\n",
      " 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1.\n",
      " 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1.\n",
      " 0. 1. 0. 1.]\n",
      "2.1870663571378524\n"
     ]
    }
   ],
   "source": [
    "# Cargamos los datos de testeo\n",
    "#-----------------------------\n",
    "data = pd.read_csv(\"test_data.csv\",skiprows = 0)\n",
    "data = np.array(data)\n",
    "X = data[:,:2]\n",
    "y = data[:,2]\n",
    "\n",
    "# Testeamos la red con los pesos aprendidos\n",
    "#------------------------------------------\n",
    "y_guess = testNetwork(W1,W2,W3,b1,b2,b3,X)\n",
    "print(y_guess)\n",
    "print(y)\n",
    "print(np.sum(y-y_guess))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusiones\n",
    "- Se comprueba que la función de costo va disminuyendo con las iteraciones.\n",
    "- Se observan dos escalones (de la función de costo), uno inicial y otro alrededor de la iteración 500 (en algunas corridas estos dos pasos son más marcados)\n",
    "- Al testear la red no se equivoca en ninguna salida...pero tengo dudas sobre:\n",
    "    - ¿Por qué no llega la sigmoidea a saturar? (no llego a tener 1s y 0s en y_guess)\n",
    "    - ¿Por qué se precisa de un learning rate tan alto?...bah...¿es alto?\n",
    "    - ¿Por qué se precisa de tantas iteraciones?\n",
    "    - ¿Cómo elegiría la cantidad de batchs? en 8 más o menos funciona\n",
    "    - ¿Me estoy equivocando en algo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
